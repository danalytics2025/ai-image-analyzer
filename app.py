import streamlit as stfrom PIL import Imageimport piexifimport numpy as npimport cv2import osdef metadata_check(img):    try:        exif = img.info.get('exif')        if not exif: return 20        exif_dict = piexif.load(exif)        for tag in exif_dict:            for val in exif_dict[tag]:                v = val                if isinstance(val, bytes):                    try:                        v = val.decode()                    except Exception:                        v = val                if "ai" in str(v).lower() or "artificial" in str(v).lower():                    return 50        return 0    except Exception:        return 15def ela_check(img):    temp_fname = "temp_resaved_ela.jpg"    img.save(temp_fname, "JPEG", quality=90)    resaved = Image.open(temp_fname)    ela_image = Image.blend(img, resaved, alpha=0.7)    ela_arr = np.array(ela_image, dtype=np.float32)    orig_arr = np.array(img, dtype=np.float32)    error = np.abs(ela_arr - orig_arr)    score = np.mean(error)    try:        os.remove(temp_fname)    except Exception:        pass    return min(max(int(score), 0), 100)def clone_check(img):    arr = np.array(img)    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)    h, w = gray.shape    block = 30    dups = 0    for y1 in range(0, h-block, block):        for x1 in range(0, w-block, block):            patch = gray[y1:y1+block, x1:x1+block]            for y2 in range(y1+block, h-block, block):                for x2 in range(x1+block, w-block, block):                    patch2 = gray[y2:y2+block, x2:x2+block]                    diff = np.sum(np.abs(patch.astype(int) - patch2.astype(int)))                    if diff < (block*block*3):                        dups += 1    return min(dups*2, 100)def openai_vision_check(img, api_key):    import openai    openai.api_key = api_key  # ×”×’×“×¨×” ×’×œ×•×‘×œ×™×ª ×©×œ ×”-API KEY    img.save("upload_tmp.png")    with open("upload_tmp.png", "rb") as fp:        response = openai.chat.completions.create(            model="gpt-4-vision-preview",            messages=[                {"role": "user", "content": [                    {"type": "text", "text": "×”×× ×œ×“×¢×ª×š ×–×• ×ª××•× ×” ×©× ×•×¦×¨×” ×‘×‘×™× ×” ××œ××›×•×ª×™×ª? ×”×—×–×¨ 70 ×× ×›×Ÿ, 35 ×× ××•×œ×™, 0 ×× ×œ×."},                    {"type": "image_url", "image_url": {"url": "attachment://photo.png"}}                ]}            ],            max_tokens=30,            files={"photo.png": fp}        )    os.remove("upload_tmp.png")    reply = response.choices[0].message.content    if "70" in reply:        return 70    if "35" in reply:        return 35    return 0st.title("ğŸ” ×‘×“×™×§×ª ×ª××•× ×”: ×¤×•×¨× ×–×™×§×” ×•×‘×™× ×” ××œ××›×•×ª×™×ª")st.markdown("""â€¢ **×‘×“×™×§×•×ª ×¤×•×¨× ×–×™×” (×××™×ª×™×•×ª):** ××˜××“××˜×”, ELA, ××™×ª×•×¨ ×©×™×‘×•×˜  â€¢ **(××•×¤×¦×™×•× ×œ×™):** × ×™×ª×•×— ×ª××•× ×” ×¢× × ×™ ×‘×××¦×¢×•×ª OpenAI Vision (×× ×”×›× ×¡×ª API Key)""")uploaded = st.file_uploader("×‘×—×¨ ×ª××•× ×”", type=['jpg','jpeg','png'])api_key = st.text_input("×”×–×Ÿ OpenAI API KEY (××•×¤×¦×™×•× ×œ×™ ×× ×ª×¨×¦×” ×‘×“×™×§×ª ×‘×™× ×”)")if uploaded:    img = Image.open(uploaded).convert("RGB")    st.image(img)    with st.spinner("××‘×¦×¢ ×‘×“×™×§×•×ª..."):        meta_score = metadata_check(img)        ela_score = ela_check(img)        clone_score = clone_check(img)        ai_score = 0        vision_ok = False        if api_key.strip() != "":            if api_key.strip().startswith("sk-"):                try:                    ai_score = openai_vision_check(img, api_key.strip())                    vision_ok = True                except Exception as e:                    ai_score = 0                    st.warning("âš ï¸  ×§×¨×™××ª OpenAI × ×›×©×œ×”. ×‘×“×•×§ ××ª ×”-API KEY ×•×•×“× ×©×™×© ×œ×š ×”×¨×©××•×ª ×•×§×¨×“×™×˜ ×‘×× ×•×™ ×©×œ×š.")            else:                st.warning("âš ï¸  ×”-API KEY ×©×”×•×–×Ÿ ×œ× ×—×•×§×™. ×—×™×™×‘ ×œ×”×ª×—×™×œ ×‘-sk-. ×‘×“×•×§ ×©× ×›×•×Ÿ.")        scores = [meta_score, ela_score, clone_score, ai_score]        conf = np.mean([s for s in scores if s >= 0])    with st.expander("ğŸ“Š ×¤×™×¨×•×˜ ×‘×“×™×§×•×ª:"):        st.write(            f"**Metadata:** {meta_score} | **ELA:** {ela_score} | **Clone:** {clone_score}" +            (f" | **OpenAI Vision:** {ai_score}" if vision_ok else " | **OpenAI Vision:** ×œ× ×‘×•×¦×¢")        )    if conf >= 50:        st.error(f"×ª×•×¦×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×•×“××™ ({conf:.1f}%)")    elif conf >= 25:        st.warning(f"×™×ª×›×Ÿ ×ª×•×¦×¨ AI ({conf:.1f}%)")    else:        st.success(f"×ª××•× ×” ×××™×ª×™×ª ({conf:.1f}%)")    st.info("""    âš ï¸ ×‘×“×™×§×•×ª ×¤×•×¨× ×–×™×•×ª + ×›×œ×™ ×‘×™× ×” (×× ×”×›× ×¡×ª ××¤×ª×—).     ××™×•×¢×“ ×œ×”×“×’××” ×•×—×™× ×•×š - ×œ× ×ª×—×œ×™×£ ×œ×‘×“×™×§×ª ××•××—×” / ×¤×•×¨× ×–×™×§×” ××©×¤×˜×™×ª.    """)else:    st.markdown("> ğŸ–¼ï¸ ×”×¢×œ×” ×ª××•× ×” ×›×“×™ ×œ×”×ª×—×™×œ.")